---
title: "R Notebook"
output: html_notebook
---

### Load libraries
```{r}
library(tidyverse)
library(MASS)
library(caret)
```
### Label data by COVID-19 severity 
```{r}
county_health_covid <- read_csv("../data/health_metrics_and_covid_cases_by_county.csv")
# create new column for deaths per capita
county_health_covid <- county_health_covid %>% 
  mutate(`Deaths per capita` = deaths / `Population`)
state_choice <- c("Florida") # select a state for the analysis

# lets see what the deaths per capita distribution looks like:
county_health_covid %>% filter(State == state_choice) %>% ggplot() +
  aes(`Deaths per capita`) %>%
  geom_histogram()

# correct the positive skew by applying a square-root transformation
county_health_covid$`Deaths per capita` <- sqrt(county_health_covid$`Deaths per capita`)

county_health_covid %>% filter(State == state_choice) %>% ggplot() +
  aes(`Deaths per capita`) %>%
  geom_histogram()

# calculate mean and std deviation for deaths per capita for the chosen state
subset_by_state <- county_health_covid %>% filter(State == state_choice)
std_dev_deaths_cap <- sd(subset_by_state$`Deaths per capita`)
mean_deaths_cap <- mean(subset_by_state$`Deaths per capita`)

# Creates a Severity label (low, med, high) based on the deaths per capita in each county
subset_by_state <- subset_by_state %>% mutate(Severity = case_when(`Deaths per capita` <= (mean_deaths_cap - std_dev_deaths_cap) ~ "low",
                                                                   `Deaths per capita` > (mean_deaths_cap - std_dev_deaths_cap) &
                                                                   `Deaths per capita` <= (mean_deaths_cap + std_dev_deaths_cap) ~ "med",
                                                                   `Deaths per capita` > (mean_deaths_cap + std_dev_deaths_cap) ~ "high"))
subset_by_state
```

### Create a test set and a training set for the LDA
```{r}
# drop unneeded columns
lda_data <- dplyr::select(subset_by_state, -c("County", "Code", "State", "Abbrev", "Population", "state", "fips", "cases", "deaths", `Deaths per capita`))

# drop rows with NA values, since these can't be used for training or testing
lda_data <- lda_data %>% drop_na()

# partition the data into a training set and a test set
# code for this adapted from:
# http://www.sthda.com/english/articles/36-classification-methods-essentials/146-discriminant-analysis-essentials-in-r/
set.seed(123)
training_samples <- lda_data$Severity %>%
  caret::createDataPartition(p = 0.8, list = FALSE)
train_data <- lda_data[training_samples, ]
test_data <- lda_data[-training_samples, ]

preproc.param <- train_data %>% 
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train_transformed <- preproc.param %>% predict(train_data)
test_transformed <- preproc.param %>% predict(test_data)
```

### Run the actual analysis
```{r}
covid_lda <- lda(formula = Severity ~ ., data = train_transformed)
covid_lda
covid_predictions <- covid_lda %>% predict(test_transformed)
mean(covid_predictions$class==test_transformed$Severity)
```

### Plot the training data against the two discriminants
```{r}
train_transformed
lda_plot_data <- data.frame(predict(covid_lda)$x)
lda_plot_data
#lda_plot_data <- cbind(train_transformed, predict(covid_lda)$x)
ggplot(lda_plot_data, aes(LD1, LD2, color = train_transformed$Severity)) +
  geom_point() +
  stat_ellipse(type = "euclid")
```

```{r}
hist_data <- train_transformed %>% 
  rename(`Percent over 65` = "Percent_Over_65", `Population Density` = "pop_density") %>%
  pivot_longer(cols = c(1,2,3,4,5,6,7,8,9), names_to = "variable")
ggplot(hist_data, aes(x = value, colour = Severity)) + 
  geom_density() + 
  facet_wrap( ~ variable, scales = "free_y")
```